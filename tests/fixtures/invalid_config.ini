[general_settings]
mod_assumption = example_mod_a
mod_assumptions_path = json_input/run_mods/mod_formats.json
sim_type = yue
holding_time = 5
erlangs = {'start': 250, 'stop': 300, 'step': 50}
thread_erlangs = False
guard_slots = 1
num_requests = 2000
request_distribution = {"25": 0.3, "50": 0.5, "100": 0.2, "200": 0.0, "400": 0.0}
max_iters = 10
max_segments = 1
dynamic_lps = False
allocation_method = first_fit
k_paths = 3
route_method = k_shortest_path
save_snapshots = False
snapshot_step = 10
print_step = 1

[snr_settings]
snr_type = None
xt_type = without_length
beta = 0.5
theta = 0.0
input_power = 0.001
egn_model = False
phi = {"QPSK": 1, "16-QAM": 0.68, "64-QAM": 0.6190476190476191}
bi_directional = True
xt_noise = False
requested_xt = {"QPSK": -26.19, "16-QAM": -36.69, "64-QAM": -41.69}

[rl_settings]
device = cpu
optimize = False
is_training = True
path_algorithm = ucb_bandit
path_model = greedy_bandit/NSFNet/0617/16_47_22_694727/state_vals_e750.0_routes_c4.json
core_algorithm = first_fit
core_model = greedy_bandit/NSFNet/0617/16_57_13_315030/state_vals_e750.0_cores_c4.json
spectrum_algorithm = first_fit
spectrum_model = ppo/NSFNet/0512/12_57_55_484293
# Only for DRL
render_mode = None
super_channel_space = 3
# Only for q-learning
learn_rate = 0.01
discount_factor = 0.95
epsilon_start = 0.2
epsilon_end = 0.05
reward = 1
penalty = -100
dynamic_reward = False
# TODO: Sim helpers has not been updated for this! (Only support for 2)
path_levels = 2
decay_factor = 0.01
core_beta = 0.1
gamma = 0.1

[ml_settings]
deploy_model = False
output_train_data = False
ml_training = True
ml_model = decision_tree
train_file_path = Pan-European/0531/22_00_16_630834
# train_file_path = USNet/0531/21_16_21_157019
test_size = 0.3

[file_settings]
file_type = json
